{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rT3-OxbCPypc"
   },
   "outputs": [],
   "source": [
    "# @title 1. Install Dependencies\n",
    "!pip install -q torch transformers accelerate safetensors huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 2. Import Libraries & Mount Drive\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "from google.colab import drive\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from safetensors.torch import save_file\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Authenticate with Hugging Face (Required for Mistral Base)\n",
    "from huggingface_hub import notebook_login\n",
    "print(\"Please enter your Hugging Face Write Token (required for accessing Mistral Base):\")\n",
    "notebook_login()"
   ],
   "metadata": {
    "id": "Kz_B5YUVQFz1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "07a4058a574346ffbe092f6d1181a35e",
      "9b15c4cf00734e019a65558b61cde0e6",
      "228a0e314e2e4471bfebd8f18e0ead81",
      "5441bb9bd689416e822019d614be811b",
      "30d804e75abb4c04a06f031e236cfcfc",
      "9f4fa65dc4ca46368b20c1d693af0125",
      "f06f32c8cf234455b27567f730f49c61",
      "8cd349a74afb4a05ba3a9af76ec121ff",
      "d7f259beaf6c4941b2397ad755c77d78",
      "d9edf41e865a479987a59a2555eae077",
      "c3aed838ca234b9ab06b83289a224fce",
      "58bbfc6761bb4469ae020c5689c4c8f1",
      "aea3eb5ae9be4131b92bac72e320bb28",
      "b1fa77cd22c142a2b84ce77033052120",
      "5c68073b4d774e5e95d6ba49482de373",
      "59fe5a4c09694fb1a418a4173a917a37",
      "99a9a5ecfa8b45b1ab2e4ea6172ee690",
      "e00530602a6c421f8908a5d91a9eb668",
      "dfea7424c84b48a89e365714ec61c776",
      "16a5cd7cf815419cb7421bb935dfd3fb",
      "730cdc945ba647efb61bc4d838addd6f",
      "8e1c0d34f91b46aabea41b1d75d4ba84",
      "0a6ae4356dd7485686848fb6a7497b96"
     ]
    },
    "outputId": "f6a3adb3-483a-4fc5-9059-2c866d08f327"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "Please enter your Hugging Face Write Token (required for accessing Mistral Base):\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07a4058a574346ffbe092f6d1181a35e"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 3. Define TIES Merge Function (Optimized for usage)\n",
    "def ties_merge_weights(base_w, model_ws, density=0.5, lam=1.0):\n",
    "    \"\"\"\n",
    "    Optimized TIES merge for single layer weights.\n",
    "    \"\"\"\n",
    "    # 1. Calculate Deltas\n",
    "    deltas = [w - base_w for w in model_ws]\n",
    "    stacked_deltas = torch.stack(deltas, dim=0)\n",
    "\n",
    "    # 2. Sparsify (Trim)\n",
    "    # Calculate threshold for top k% magnitude\n",
    "    k = int(stacked_deltas.numel() * density)\n",
    "    if k < 1: return base_w # Skip if density is too low\n",
    "\n",
    "    magnitude = stacked_deltas.abs()\n",
    "    # torch.kthvalue is slow on large tensors, simple sort is often faster for 1D\n",
    "    # flattening effectively puts all params in one list\n",
    "    sorted_mag, _ = torch.sort(magnitude.flatten())\n",
    "    threshold = sorted_mag[-k] # The value at the cutoff index\n",
    "\n",
    "    mask = magnitude >= threshold\n",
    "    sparse_deltas = stacked_deltas * mask\n",
    "\n",
    "    # 3. Elect (Sign Consensus)\n",
    "    signs = torch.sign(sparse_deltas)\n",
    "    summed_signs = torch.sum(signs, dim=0)\n",
    "    consensus_sign = torch.sign(summed_signs)\n",
    "\n",
    "    # Filter disagreements\n",
    "    consensus_mask = (signs == consensus_sign)\n",
    "    filtered_deltas = sparse_deltas * consensus_mask\n",
    "\n",
    "    # 4. Merge\n",
    "    summed_deltas = torch.sum(filtered_deltas, dim=0)\n",
    "    num_contributors = torch.sum(consensus_mask, dim=0)\n",
    "    num_contributors = torch.clamp(num_contributors, min=1.0)\n",
    "\n",
    "    final_delta = summed_deltas / num_contributors\n",
    "\n",
    "    # 5. Apply\n",
    "    return base_w + (lam * final_delta)"
   ],
   "metadata": {
    "id": "SuMZKsgRQJs1"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# @title 4. Execute Layer-wise Merge\n",
    "\n",
    "# --- HELPER FUNCTION FOR VOCAB MISMATCH ---\n",
    "def align_and_pad(base_t, model_ts):\n",
    "    \"\"\"\n",
    "    Checks if tensors have different vocabulary sizes (e.g., 32002 vs 32000).\n",
    "    If so, pads the smaller ones with zeros to match the largest.\n",
    "    \"\"\"\n",
    "    # 1. Check shapes\n",
    "    shapes = [base_t.shape[0]] + [t.shape[0] for t in model_ts]\n",
    "    max_vocab = max(shapes)\n",
    "\n",
    "    # If all shapes are the same, return as is\n",
    "    if all(s == max_vocab for s in shapes):\n",
    "        return base_t, model_ts\n",
    "\n",
    "    print(f\"  [Auto-Fix] Resizing vocab from {shapes} to {max_vocab}...\")\n",
    "\n",
    "    # 2. Define padding function\n",
    "    def pad_tensor(t, target_len):\n",
    "        current_len = t.shape[0]\n",
    "        if current_len == target_len:\n",
    "            return t\n",
    "\n",
    "        # Calculate how many rows to add\n",
    "        diff = target_len - current_len\n",
    "\n",
    "        # Create zeros of the same data type and on the same device\n",
    "        # We assume the tensor is 2D [vocab, hidden_dim] (like embed_tokens or lm_head)\n",
    "        zeros = torch.zeros((diff, t.shape[1]), dtype=t.dtype, device=t.device)\n",
    "\n",
    "        # Concatenate along the vocab dimension (dim 0)\n",
    "        return torch.cat([t, zeros], dim=0)\n",
    "\n",
    "    # 3. Apply padding\n",
    "    base_t = pad_tensor(base_t, max_vocab)\n",
    "    model_ts = [pad_tensor(t, max_vocab) for t in model_ts]\n",
    "\n",
    "    return base_t, model_ts\n",
    "\n",
    "# --- MAIN EXECUTION ---\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "base_model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_paths = [\n",
    "    \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
    "    \"Gryphe/MythoMist-7b\"\n",
    "]\n",
    "merged_model_name = \"MyMergedModel02-7B\"\n",
    "save_path = f\"/content/drive/MyDrive/{merged_model_name}\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# TIES Parameters\n",
    "density = 0.5\n",
    "lam = 1.0\n",
    "\n",
    "print(f\"Starting TIES merge (Robust Mode)...\")\n",
    "\n",
    "# 1. Load Base Model Structure (CPU)\n",
    "print(\"Loading Base Model structure...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"cpu\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 2. Save Tokenizer from the LARGER model (OpenHermes) to ensure special tokens exist\n",
    "print(\"Saving tokenizer from OpenHermes (to keep special tokens)...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_paths[0])\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "base_state_dict = base_model.state_dict()\n",
    "keys = list(base_state_dict.keys())\n",
    "new_state_dict = {}\n",
    "\n",
    "# 3. Load Source Models (CPU)\n",
    "print(\"Loading Source Models...\")\n",
    "model_1 = AutoModelForCausalLM.from_pretrained(model_paths[0], torch_dtype=torch.float16, device_map=\"cpu\")\n",
    "model_2 = AutoModelForCausalLM.from_pretrained(model_paths[1], torch_dtype=torch.float16, device_map=\"cpu\")\n",
    "\n",
    "print(\"Merging layers...\")\n",
    "\n",
    "for key in tqdm(keys):\n",
    "    # Retrieve weights\n",
    "    base_w = base_state_dict[key]\n",
    "\n",
    "    # Check if this key exists in the fine-tunes (sometimes structures vary slightly)\n",
    "    if key not in model_1.state_dict() or key not in model_2.state_dict():\n",
    "        print(f\"Skipping key {key} (missing in one of the models)\")\n",
    "        new_state_dict[key] = base_w\n",
    "        continue\n",
    "\n",
    "    w1 = model_1.state_dict()[key]\n",
    "    w2 = model_2.state_dict()[key]\n",
    "\n",
    "    # Skip non-float parameters (like tracking stats)\n",
    "    if base_w.dtype not in [torch.float16, torch.float32, torch.bfloat16]:\n",
    "        new_state_dict[key] = base_w\n",
    "        continue\n",
    "\n",
    "    # --- FIX: ALIGN VOCAB SIZES ---\n",
    "    # This detects if w1 is 32002 and base is 32000, and pads base/w2 with zeros\n",
    "    base_w, [w1, w2] = align_and_pad(base_w, [w1, w2])\n",
    "\n",
    "    # Apply TIES\n",
    "    try:\n",
    "        # Move to GPU for calculation\n",
    "        res = ties_merge_weights(\n",
    "            base_w.to(\"cuda\"),\n",
    "            [w1.to(\"cuda\"), w2.to(\"cuda\")],\n",
    "            density=density,\n",
    "            lam=lam\n",
    "        )\n",
    "        new_state_dict[key] = res.to(\"cpu\") # Move back to CPU to save RAM\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU Error on {key}, falling back to CPU: {e}\")\n",
    "        res = ties_merge_weights(base_w, [w1, w2], density=density, lam=lam)\n",
    "        new_state_dict[key] = res\n",
    "\n",
    "    # Explicitly delete tensors to free memory immediately\n",
    "    del base_w, w1, w2\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Cleanup\n",
    "del model_1\n",
    "del model_2\n",
    "del base_model\n",
    "gc.collect()\n",
    "\n",
    "# Save\n",
    "print(f\"Saving merged model to {save_path}...\")\n",
    "save_file(new_state_dict, os.path.join(save_path, \"model.safetensors\"))\n",
    "\n",
    "# Save Config\n",
    "print(\"Saving config...\")\n",
    "base_config = AutoModelForCausalLM.from_pretrained(base_model_name).config\n",
    "# Update config vocab size to match the new larger size\n",
    "base_config.vocab_size = new_state_dict[\"lm_head.weight\"].shape[0]\n",
    "base_config.save_pretrained(save_path)\n",
    "\n",
    "print(\"Merge Complete! Model saved to Google Drive.\")"
   ],
   "metadata": {
    "id": "4TLZN0nvQVsu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "10d109342acd44f8afc0a4958331aa50",
      "2c0030cc62ae483a882b8a838880fd6a",
      "7007ab1106a941038ef04fcf43fbf0ec",
      "cc50c8a3df5b4277b03f3b79346c3ce9",
      "8820bb62009e4cc48024e22d912bdc0c",
      "197acc3f5c8d48b3bee5ed37e91d4401",
      "0bc6fbd31a234360bd8c78c26d2e8c77",
      "5df56c858f614eac9a99cc1ca3d26a34",
      "e251047e86d34a22b1d9ffa94651f286",
      "efe5dcd0b51843e8bdb561ca83c88d26",
      "8cfb52fb133248518b1fe22c97f3c12c",
      "75baba342ecc490c835b0c1332c0abfb",
      "2a8864a861aa4bf5b69d64d3e5d3cad9",
      "ac8a0bec94e749699cc0fc8ac45480f6",
      "198612e0dd6942ad8a35ae304751b237",
      "6cb2aed30bdf4f31bb2a089223425991",
      "2fa8b4d2599c41d5bad40b11a1fdeaa4",
      "09fcd397a3b64639bf0c90708b872c89",
      "280ac5fda6ae405e9a212c2259fb5905",
      "6aa5ba1f8e034d7d839454603d9bd575",
      "a070da84c040403188e993193bc3fdc5",
      "0b3ae2588e9c4749aff263b9ab0b31f0",
      "e9d14c9414ff49c08ca00b63be126a7f",
      "4cae4a837cf74a338e5e17ac8c1d969e",
      "291563b46a8049168b99a6a432dc46b5",
      "251f662c6c2848c9bea10f91ca57996b",
      "fad0222942424213bc2cebb4e000b972",
      "1950a800424f461fb24e4d9257f53fe3",
      "a3240c4c83c240dab1e1875d554dc60f",
      "74b28caf769d4f209abb14196067104a",
      "a4890fd244c94a5d88e9509ddf35e4c3",
      "91fbc6e9a5eb424b8b5c2e5d26f0f0ae",
      "b983204a89b54c3ebe5ca91ce36588e2",
      "4a6c3206739e458f9d63e4a3297ab771",
      "7d3bd5d7590e4b0d93a27418576a8e91",
      "3dec9d31671f46138ed6fdb504957377",
      "a83033dd30804c6ba3d519551e737314",
      "c4578f1c64624d9487fafe3441ca7dc6",
      "ffbab87c16284294b8035faa85775f8a",
      "11d44a3ea0fd4971a7f030f679c19851",
      "b95efe32f9f442a39b83b42cc99dd28b",
      "a7fb0baca360473e99af902901832671",
      "ffa18d319a8b40e98c575842fcc74439",
      "a4fe9e6b2dc24458bf60957fa0efad4e",
      "94670a2dce5841a88ffee07c2c0d60bc",
      "2ac3fc0ad32f40ebbc9e7fa4515fdf5e",
      "63f33872ec554590bc7add6981a92c88",
      "35d8f70464e247b39c3d5831b756e537",
      "450798b386e043eba01be57575c00113",
      "6bf02c8ede30417dbc9769e8f7e99968",
      "7268ee8a53164f5e9ece3df73f4b0537",
      "bc59779ff1db41e1a0d41f984a6a4f7e",
      "f020768603ea4c7484e84ead0a64277e",
      "5270e6c4c73c4d44a133cb8ec0af2a8a",
      "00a339a9faa64791a6f3f8106870a0f2",
      "6ab1bf8a48114a98a03afbb90306e262",
      "c90b20ff2e9345189cd61e35b39c614a",
      "6e6cab67f7944361b072e689ffa15986",
      "b8461803b18f4d6cb5bc2249242fff96",
      "14b68a8022db4541930933143a3bb031",
      "ff682d4062404d12b303bb3bdaee49fa",
      "83b98f673b58409c9e35091ccde0ddf6",
      "43b9333ffd2d4fccac53a61f38e2ddeb",
      "f588a4e3414143cb840c2f175c87d758",
      "06d8f964f8094a689ccd38eda0d0574b",
      "62fb80c7d565455e8d8bfe34affff145",
      "a40a2a250e524c4e83027de3ae1b626d",
      "9c042f514b3847ebb1425831f7e19778",
      "af5ff56c9b8341eaad1b5e2d8654f79f",
      "e47c3b73a4a34233a016ddf69ba57273",
      "95420a79298f46e88cc02e507741f98d",
      "b7849b751bdd4cbc949211a66c724352",
      "f2630f8d85ac4221a7889df527262b70",
      "094d8ae3975c4ec3968bf44aaf6ed5cc",
      "0e2022f8999d4e9e895c32389e2a7b18",
      "8e690f98742c45028b936a20ea23073c",
      "7f9774f74381429e881401b910ce663b",
      "c28ab508a24240e8942b46df1cfa572d",
      "a4486686dea0431e8642e26101a33dd2",
      "cefd8c5316a04504990a4387e80b6d62",
      "73ab8f7c978d4eebb7aa6aebc5513213",
      "4a2a325f92bc46f3b7387283d297ca3a",
      "3fc1385f780241ac92725400fd0893f1",
      "7f63feba69914af3b042ccefef451701",
      "a1d3f06224954ad285e1ad6e4c73c42b",
      "44008b4d74134146ae57d802d13f0ed5",
      "640ca8e9478d4805a18826c9d845d0f5",
      "365731aa249f4a40afdb6543525456f0",
      "5e92df0f42384c98a3a79b4e7fa82487",
      "055854b5874f420994776188deaeba66",
      "5b237bf0f358440f9dbc78dade1d1ec2",
      "93e2ceb99f2742dfb4e35472fcb9277d",
      "21cf932bd071422fb3b788c639a8b254",
      "a2fc3472fa3a4ab2b4f4ca692697e7fa",
      "c3fdd6033b7e42319ab14979635eb99e",
      "a883e41c5aec4a7faf4e6f369de61911",
      "b729347eb1b644d9bb8d913e5aa82842",
      "86954637361347f5a9b4f92cf62ef3f9",
      "52c5f2a8408440edba1ec8c7cec63c6c",
      "34d0f35390044d699c1a6bb820f4398e",
      "93cd31e16a48473e8d47d34fbb92f51e",
      "5b86ef4691514485959af4760b6ca748",
      "695e14285da9462da7beeca1b2c4d6c3",
      "e7870233ca0e4e4c8f9f2bfc4f2eb65e",
      "5f7486ab24a54c60b0483591735f251a",
      "f089536d7f384cdea0333bf123e00455",
      "ba225d475f484990b5aaf824c8d8fea4",
      "283797ef539944c3b84b98209e230959",
      "778ba06068e3446c85e77a9fe580b414",
      "d9acdf601ec341baac9aed7469215214",
      "ea41d4d671b7463886d9e042230c4d46",
      "e0414370230c4e768a93d435b258dcd2",
      "78a416f26b9540798c5f4141f916a011",
      "fce90df188ec48e2b865aa871ead810c",
      "f14eb2eb78344411a0fdb7cbf4e27d20",
      "bc7f88508fc24c8b9829b05194143f89",
      "7ec8f185315b42ceaeca61f532936e9c",
      "56e58eb21a2b459594f84a9ca8699f04",
      "c96d3f03c181416fb1218cf382df01f6",
      "83da2d7a292749eaade2389e33bda72e",
      "af84504136fd4832a257d34e782ef0b4",
      "0d232d7a733244e2993c09dddd547a38",
      "35619e67bdb04fe999dd5c3d3c7c3d72",
      "a31c79493b354e9fa0438308b4f7fb17",
      "8795b72a2eae474997f883bd5179a06f",
      "1a3d1f31153d4bedbd7c0f4e72175508",
      "224b3c8084d14a5191ff92277365aa11",
      "318be235219e47258a4a518511910b32",
      "ec5f2c85676546598d4a2f3f301a2c54",
      "257152209b9e40c6bc3aaf07797e3220",
      "2c657ae201694040843d4feabc8e3af4",
      "502a11899cbe4bceaffdba05a23d07a7",
      "b094f1e7e591417a806e0da98ed3aa03",
      "623ef6a7422c4a7fbe4b911642e932fe",
      "3dcfb8e768c746b9ba046983883eb3d8",
      "7ec9a8f776b347ec8f5ff15bf5faed82",
      "3f75d4ddd3164e6ebfcd6a8ad076169b",
      "2d6bec0d35c24306b0dab856efd9ab1b",
      "83f8a1db66ab43f2a0f57735130428fc",
      "7c78d152927d4cd9a86258a7434945c0",
      "39d3fc2b6db24f0ab7829df66d3432bd",
      "a25906069ffc4ea5ac27e5ebd8c30fef",
      "f381d2482e894d02ba3716bc6c9079dd",
      "8bfae152780f493b81891b07f0b1f145",
      "9b82e37004234b2d899eb10b30a98f53",
      "2d556e81b53d4b1584513c975d35131d",
      "c8967a49b1484a1ebe060a10280a9425",
      "1811956e2bc34eb5bfae4a269882094e",
      "0e106966a0404d809110b515d9520cdf",
      "a8f2406d4243472da1a284188b971d38",
      "5244b9186da947d68a250bfd31c0bc12",
      "efb333d2e15343b8a535c04983cb9abe",
      "455b1e0b451b4374b775db6138f1042a",
      "bbea0a732cfb485baad26ca54b57442f",
      "933dc6c6ffa64a63beb24b4989f5865c",
      "bca2600873b645d0a8802b579c986a0a",
      "463d04d8e7ad4838ac69cdb89a46bbea",
      "07270818f9e8494ba4de43fef22bcb7e",
      "10049d076a834fe8820970e2fb8aa325",
      "e62bfd76527744baaa67803f5f1cf84e",
      "e35e6b1ef6c94d7eb8be0eaaf3f8bf93",
      "ee08367b62ff4c8eb7710766efc24274",
      "bf6dbad7d211449ca7a084146f00e640",
      "793fa8f540d541f598802cd45ac73020",
      "eb9dc32f62cd4fb79f2753313044f742",
      "6f03866298ed4b1eafb5ab2a1396188b",
      "8c3d2ad51c4e43629310dbbd56da5c5c",
      "cd91619cef8944a1aa23779a51d72edc",
      "d59175d10be9475799787e2d0fcf2349",
      "eeb06f6fa2e94f1697c5bf4ff2d776dd",
      "7c79d2f3a4cf4df0917ff40f4b9b5138",
      "823ee5223d484c47bd2630d252327179",
      "a33f08447f864bd1bf9549bd32f050a7",
      "e6ecfc06583e4b69b77876f3437f86bc",
      "97af6f82b8ec4208b277d7c0e2eec34d",
      "0b4b8c77b3a240b598e14be159e90cf4",
      "95d939637851448088c8083bfd1aacf6",
      "8172ff66b9324e24af3715ce59b91f2e",
      "2aa49a99a8c74100b26212a0d7d31a85",
      "9c5e026f12fc4b05bde01587f5c308e8",
      "7f971fe0a52a44548fb0f9704ad324ef",
      "6547859ccb754e3a88ccc2b705e4d794",
      "7db03dba64214be9a1ba1d78ffc0a633",
      "0a8b8a8aec6c43eaa468b0ad045f92a1",
      "7e7c61aa06254ead80b9a7bd85cbc5d8",
      "3f427e9232da49ca95a7f7976c657bdf",
      "a8083f3a64f046f88bbe099e315b1000",
      "b090f3cfdd4945deb2736c17b42beffa",
      "27a339a4e55342378f908e66a4df7504",
      "ed4c64a8172e4db8a70a33deaafed4be",
      "68018c407cfc444582ae1719b2290b21",
      "4fa6e9bc678f4d0a92384ea3311f044f",
      "2d2e29c7965748c9bbff47435326d5a7",
      "cb19eaf79848410ea65f034355ed5231",
      "fd4a660ae3f947b09209ff666dc4c9ff",
      "7fed943823714f8a8f86757378049275",
      "83ade37b35be4d948008b86758ee6cbc",
      "63bdd14bfaca46be9bc33dff5a60d151",
      "437f836b6eac434a9921222c35de354e",
      "859b8d3cd1374bb180747b86dabcf0e9",
      "12352370b4644f51b175c63675f83d91",
      "6863fb8ea078446884b44c29e9c1b63d",
      "1f8ff18f075148219a281aa8b44366ec",
      "41f2a45578a944528c2de99705ae9e26",
      "436c6b3e047d452ca24d27486c855db4",
      "d13f9c0e15d040d6b88df32a2cb4592a",
      "3d165cb857e745e5812648672582da6b",
      "615a6240f2ad43e28b3f86e62824adb0",
      "c6fb7adc50c74a87ac667e838b930d5f",
      "35675d0f4aa943f28a14d9ec553f3ef1",
      "d82b863b4aaa4cc5af2c54fde9f75cc0",
      "38181872a4a74f8d94cdf4a72ad1b0fd",
      "7e07de17fabd4d75871f5073a644c08f",
      "b255bd4d1df1414fac7a49f55813a62e",
      "fcd263c546634342b82643dc380de3e6",
      "52fdd1f776a24a6bba3fb33ddf4f4716",
      "917da55aab3b411d9014c5dd28de567c",
      "eb19193fe4f74044aa3a9c935c43d9fd",
      "d23ea81162c648e99fc1ea3a3d90881c",
      "3bc399c9b69c44d18a71c56430ee8213",
      "6af42eae5031433b82dabf5ec42050e5",
      "a2a4104e575645fda5190c37f9f4d0dd",
      "c6739dd7aead4e65a61248066233a70e",
      "8f418992869645698cb14527f2fbc816",
      "3300c9f830454a15b573d4d8518e2ec8",
      "07158ee985fa4616a434832c62356a44",
      "efa10ae86ef04271a935039bf54f91b0",
      "27c909ca0f3740c49de5d4e10c10164f",
      "f35ba8a19cb54334b82309eb1ec68a30",
      "b0997623436e4f9fa7dccf7feebc554f",
      "930e875b57e34668962d001c0e5d0d03",
      "1e45827c368f4a1b885dab9495d37dff",
      "55d2987cf38b4b1f86327da6f445023c",
      "655caa71b2fe4b2188a9e86996bd481b",
      "ab9d62a2b72c4ecd92c176edc110347b",
      "81b2d6de63714fb9a5f61fbeeffe97b9",
      "8389357b6be54986a6e3e5dffc631fb2",
      "238bb71096f44798a05fb741c1b25b69",
      "543d7954df5a40f38f8edb9225ca5d69",
      "e8170431581d4ea98a0cc385a3e9b4c9",
      "c6edd6f4af814856867ba0f0b44d198a",
      "afbfd4f545ae45dba721e797be68c1bd",
      "183a2907e648453f855dac8845817ccd",
      "dc9f7b1b8dc64ecb9e857727a7385a44",
      "6ada1b175cc94594a87b20f39cf15156",
      "568cd25915a7460cb02d22a3048c170f",
      "f93c82a6f08a443db9868637d44611b8",
      "a270833290a147eca7cf8b2c47fffb6d",
      "eaee8833b27e48818b66d58a3507784b",
      "5f6cdce99d0f44228d4210342a20fe9f",
      "c3e7c8619a254ba38a5898b776a94e42",
      "a7dec93275a148ad819b3024aee60cdd",
      "9dab273b5d724793bd4dbe2c0e87414b",
      "b90cfff99cf64ce1b77e370ba90993fd",
      "d970235e59684c72a09310a979a1c933",
      "ad587e8037604265b195c6bf8ba5350f",
      "c784ca20405a4e0882670816dc8bb3ef",
      "0be08131d8d840d082e9def4332bd3d2",
      "cc34d0cb5baa4645a8397204a85b2fb9",
      "377075a1d3c5480ca83695f5e1174695",
      "3da7ff60a0484a43ac2ebc296896fc1b",
      "a5819bc1bca1498da7decb55c0abc71d",
      "5e4bb0d739254157bcae75696e374f2b",
      "71ffb6f276094981b1e2f64cc268c361",
      "0f75febc1f4d42afa10ea3be430fea5f",
      "e743966f81b340e2bc4a2d526405f5cf",
      "7563b3ba8ce6420795c05bfda221ae6a",
      "1f753489211b43b6af9d1a1b552519a0",
      "321526ee0a674ca29de967ee765f973f",
      "20903618d3b140388663814304e49cc2",
      "ba6e143f682a4abba5b92e7800345c4e",
      "cd500197d31143b48baac390475d374f",
      "7ac802d81602440fbf3b831aaf1a26ee",
      "23792df756a248a9a3201dff267bed30",
      "76d7855950e342d4b35c0e8596e62cd3",
      "a2073e73f74a4c809d35f3dadf4ee0a2",
      "b274cb4f12af4f82b9ae42f86c892d60",
      "5bc818b4acd34b188e5e6bb0bb47ad5f",
      "bd6f09fccd5b48aaba558ec00bc0a222",
      "229d1777cd00471fb402c6185e9ef6fb",
      "9f201cf07e314d33b28d7dbaa3a95f5c",
      "3ecda749413e4eedaabcbad141f3184e",
      "e00c254871054968bcfa2a3b9d573eb2",
      "ff7c7256f2174cf995cbb57522b22f08",
      "5284f13aa4f0461790b505691f1870d0",
      "a9f3693e802e4ad992a0a681b08c2b2a",
      "7dcfac29c3f142319d538d5e8b5ec68c",
      "1777caf3a95747948da26069dc8ac9d7",
      "d6e57ddebd8141899a1e4dae2072339c",
      "a6e7f28814bd4e97b80e4c3d5ada59a7",
      "cb9e5c84044e4904b3f21c6242df2727",
      "c7137b35125b4130bc911ff8653097d9",
      "137a5498894b47ebbf50a95cd89bfdec",
      "a29a83043d8f4c1cb41f50552d8f043a",
      "719d7c5b97fd48a98e017f6dc9d4ac19",
      "78dec2c8efe341c4b1fc7355246f5a8d",
      "eacef3c9533d4d389ca97049dae8a4fa"
     ]
    },
    "outputId": "6ccbeeed-514b-4d3d-bc6e-42e575ea012b"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting TIES merge (Robust Mode)...\n",
      "Loading Base Model structure...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10d109342acd44f8afc0a4958331aa50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75baba342ecc490c835b0c1332c0abfb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9d14c9414ff49c08ca00b63be126a7f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a6c3206739e458f9d63e4a3297ab771"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94670a2dce5841a88ffee07c2c0d60bc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ab1bf8a48114a98a03afbb90306e262"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a40a2a250e524c4e83027de3ae1b626d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving tokenizer from OpenHermes (to keep special tokens)...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c28ab508a24240e8942b46df1cfa572d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e92df0f42384c98a3a79b4e7fa82487"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34d0f35390044d699c1a6bb820f4398e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea41d4d671b7463886d9e042230c4d46"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading Source Models...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d232d7a733244e2993c09dddd547a38"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b094f1e7e591417a806e0da98ed3aa03"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bfae152780f493b81891b07f0b1f145"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "933dc6c6ffa64a63beb24b4989f5865c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f03866298ed4b1eafb5ab2a1396188b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95d939637851448088c8083bfd1aacf6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b090f3cfdd4945deb2736c17b42beffa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/600 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "437f836b6eac434a9921222c35de354e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35675d0f4aa943f28a14d9ec553f3ef1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6af42eae5031433b82dabf5ec42050e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e45827c368f4a1b885dab9495d37dff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "183a2907e648453f855dac8845817ccd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b90cfff99cf64ce1b77e370ba90993fd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f75febc1f4d42afa10ea3be430fea5f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2073e73f74a4c809d35f3dadf4ee0a2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Merging layers...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/291 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  [Auto-Fix] Resizing vocab from [32000, 32002, 32000] to 32002...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 99%|█████████▉| 288/291 [00:41<00:00,  6.20it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  [Auto-Fix] Resizing vocab from [32000, 32002, 32000] to 32002...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 291/291 [00:41<00:00,  6.97it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving merged model to /content/drive/MyDrive/MyMergedModel02-7B...\n",
      "Saving config...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dcfac29c3f142319d538d5e8b5ec68c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Merge Complete! Model saved to Google Drive.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title: 5. Testing the Merged Model\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Path to our saved model on Drive\n",
    "saved_model_path = \"/content/drive/MyDrive/MyMergedModel02-7B\"\n",
    "\n",
    "print(f\"Loading merged model from {saved_model_path}...\")\n",
    "\n",
    "# Load Model & Tokenizer\n",
    "# We use device_map=\"auto\" to put it on GPU for inference\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    saved_model_path,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
    "\n",
    "# Test Prompt\n",
    "prompt = \"Explain the concept of quantum entanglement to a 5-year-old.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "\n",
    "# Apply Chat Template (OpenHermes uses ChatML usually)\n",
    "# If the tokenizer doesn't have a chat_template, we format manually\n",
    "if tokenizer.chat_template:\n",
    "    inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
    "else:\n",
    "    # Fallback manual formatting\n",
    "    input_text = f\"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "print(\"Generating response...\")\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(\"-\" * 50)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fXWrk5xOZUp8",
    "outputId": "ddf9d3ed-48f7-48cf-da13-80234e47904c"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading merged model from /content/drive/MyDrive/MyMergedModel02-7B...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating response...\n",
      "--------------------------------------------------\n",
      "system\n",
      "You are a helpful assistant. \n",
      " user\n",
      "Explain the concept of quantum entanglement to a 5-year-old. \n",
      "\n",
      "Imagine you have two best toy friends, let's call them Toy A and Toy B. Even when they are far away from each other, they still share a secret bond. They can feel what the other is feeling without actually talking to each other. This special connection is called quantum entanglement. In the world of tiny things called particles, this bond can exist between two particles. When something happens to one particle, the other one reacts to it instantly, no matter how far they are. Just like your toy friends, they know they are connected and share a secret bond, even without seeing each other. This is a very mysterious and special thing that only happens in the world of very, very small things.\n",
      "--------------------------------------------------\n"
     ]
    }
   ]
  }
 ]
}